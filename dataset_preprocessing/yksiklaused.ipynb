{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperiment 3 eeltöötlus\n",
    "\n",
    "Erinevus eksperiment kahest:\n",
    "* Juurde on lisatud ükskilausete korpus (tehtud sarnane eeltöötlus kui otsekõne ja jutustaja korpustele)\n",
    "* Varasemalt mitte kasutatud testhulgast on lauseid validatsioonihulka juurde lisatud, et see oleks stabiilsem.\n",
    "\n",
    "Kokku lauseid treeninghulgas:\n",
    "Kokku lauseid validatsioonihulgas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Üksiklausete tekstide ja wav-failide eraldamine kaustadesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_1 = \"\"\n",
    "sentences_2 = \"\"\n",
    "yksiklaused_wavs = \"\"\n",
    "\n",
    "yksiklaused_txt_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    if line.str.startswith('eki_et'):\n",
    "        line = re.sub('\\t([0-9:]+)?\\t\\t', '\\tx\\t', line)\n",
    "        parts = line.strip().split('\\tx\\t')\n",
    "        assert len(parts) == 2\n",
    "        wav_file_name = parts[0]\n",
    "        sentence = parts[1]\n",
    "\n",
    "        txt_file_name = wav_file_name.split('.wav')[0] + '.txt'\n",
    "        with open(yksiklaused_txt_path + f'/{txt_file_name}', 'w', encoding='utf-8') as fout:\n",
    "            fout.write(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Üksiklausete failide ümbernimetamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yksiklaused_txt_path = \"\"\n",
    "yksiklaused_wav_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(yksiklaused_wav_path):\n",
    "    if filename.endswith('wav'):\n",
    "        # 'eki_et_ptr_10015.wav'\n",
    "        orig_fname = filename.split('.')[0]\n",
    "        no = orig_fname.split('_')[-1]\n",
    "        new_name = 'yksiklause_' + no\n",
    "        shutil.copyfile(os.path.join(yksiklaused_wav_path, filename), os.path.join(yksiklaused_wav_path, f'{new_name}.wav'))\n",
    "\n",
    "        # Üksiklausete tekstifailide ümbernimetamine\n",
    "        txt_filename = orig_fname + '.txt'\n",
    "        shutil.copyfile(os.path.join(yksiklaused_txt_path, txt_filename), os.path.join(yksiklaused_txt_path, f'{new_name}.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Liiga väikeste ja suurte failide eemaldamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_selection = [] # Files from the folder that are in certain size range\n",
    "files_discarded = 0\n",
    "files_included = 0\n",
    "\n",
    "for file in os.listdir(yksiklaused_wav_path):\n",
    "    fsize = os.path.getsize(os.path.join(yksiklaused_wav_path, file))\n",
    "    if fsize < 44000 or fsize > 1000000:\n",
    "        files_discarded += 1 \n",
    "        continue\n",
    "    files_included += 1\n",
    "    sample_file_selection.append(file)\n",
    "\n",
    "print(f'{files_included} files included in datasets. {files_discarded} files discarded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Treeningandmete jagamine ja teiste treeningandmetega kokku liitmine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(sample_file_selection, train_size=0.9, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Üksiklauste lisamine treening- ja validatsioonihulka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentence_from_file(sentence: str, txt_folder):\n",
    "    if not sentence.endswith('.txt'):\n",
    "        sentence = sentence + '.txt'\n",
    "    with open(os.path.join(txt_folder, sentence)) as f:\n",
    "        sentence_text = f.read() + '\\n'\n",
    "    return sentence_text\n",
    "\n",
    "def compose_txt_for_training(wav_file_subset, wav_file_reference_path, txt_folder):\n",
    "    lines = []\n",
    "    for fname in wav_file_subset:\n",
    "        sentence_id = fname.split('.')[0]\n",
    "        wav_reference = f'{wav_file_reference_path}/{fname}'\n",
    "        sentence = read_sentence_from_file(sentence_id, txt_folder)\n",
    "        lines.append(f'{wav_reference}|{sentence}')\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: lisada pathid\n",
    "import random\n",
    "\n",
    "train_filelist_fname = 'est_audio_text_train_filelist_4400_1000000.txt'\n",
    "new_train_path = ''\n",
    "\n",
    "with open(train_filelist_fname) as f:\n",
    "    lines = f.readlines()\n",
    "    train = compose_txt_for_training(train, yksiklaused_wav_path, yksiklaused_txt_path)\n",
    "    train_set = lines + train\n",
    "    random.shuffle(train_set)\n",
    "    with open(new_train_path, 'w', encoding='utf-8') as fout:\n",
    "        fout.writelines([l + '\\n' for l in train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_filelist_fname = 'est_audio_text_val_filelist_4400_10000000.txt'\n",
    "test_filelist_fname = 'est_audio_text_test_filelist_4400_10000000.txt'\n",
    "\n",
    "# 1. Lisa üksiklausete validatiooniread\n",
    "\n",
    "# 2. Lisa  testandmestikust lisaread\n",
    "\n",
    "# 3. Andmed juhuslikku järjekorda\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matcha-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
